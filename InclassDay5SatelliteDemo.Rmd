---
title: "In class Satellite"
author: "Willem Vervoort & Rafael Navas"
date: "12 July 2018"
output: pdf_document
---
```{r setup, echo=F, warning=F, message=F}
# root dir
knitr::opts_knit$set(root.dir = "C:/Users/rver4657/owncloud/Uruguay/coursematerial")
knitr::opts_chunk$set(echo = TRUE)
require(knitr)
```

This is part of a course taught at IMFIA UdelaR in collaboration with MSc Jimena Alonso in July 2018. It is part of the project INIA-IRI-USYD.

```{r logos, echo=F}
include_graphics("logos.png")
```

Load packages

```{r}
require(tidyverse)
require(lubridate)
```

Function to extract the data from the individual files


```{r}
MODIS_ts <- function(MODISdir="MODIS",
                     patt=".asc"){
  
  # step 1: read in all the file names
   x1 <- list.files(path=MODISdir, pattern=patt)
  
  # step 2: rows and storage
  # each "asc" file stores all the values in time for 1 location
 # the number of rows is important as this is all the time steps
   # check the number of rows in the file
    n <- nrow(read.csv(paste(MODISdir,x1[1],sep="/"),header=F,
                       na.strings=32765))
    # use this information to:
    # Create storage for the data, Jdate is Julian date
    Store <- data.frame(Year = numeric(length=n),
                        Jdate = numeric(length=n),
                        ET = numeric(length=n),
                        Point = numeric(length = n))
    
    # Create an empty list to store the different pixels 
    # (each with a data frame called Store)
    # step 3: create a "master" storage list
    Store1 <- list()
    # Step 4: run a loop over the list of file names
    for (i in 1:length(x1)) {
      Mdata <- read.csv(paste(MODISdir,x1[i],sep="/"),header=F,
                        na=32765)
      # do some substringing
      Store[,1] <- as.numeric(substr(Mdata[1:n,8],2,5))
      Store[,2] <- as.numeric(substr(Mdata[1:n,8],6,8))
      Store[,3] <- Mdata[1:n,11]*0.1
      Store[,4] <- i
      Store1[[i]] <- Store

    }
    # step 5: converting from list back to a data.frame
    ts.data <- do.call(rbind,Store1) 
    # Now make the date from the Year and Jdate
    ts.data$Date <- as.Date(paste(ts.data$Year,ts.data$Jdate, 
                                  sep = "/"), "%Y/%j")
    
    return(ts.data)
}

# and we can run this function and check the data
SL_ET <- 
  MODIS_ts(MODISdir = "Data/Modis")
# Chk the data
head(SL_ET)

```

Visualise the data in a quick graph

```{r}
SL_ET %>%
    filter(Point>= 10 & Point < 16) %>%
    filter(Year >= 2010 & Year < 2012) %>%
    ggplot(aes(Date,ET, colour=as.factor(Point))) +
      geom_point(size=2) +
    xlab("8-day time series") + ylab("8-day ET in mm")
```

Show a histogram

```{r}
SL_ET %>%
ggplot(aes(ET)) + geom_histogram(fill="blue") +
xlab("MODIS ET 8 day cumulative values")
```

let's filter the 0 values
```{r}
SL_ET_no0 <- SL_ET %>%
    filter(ET > 0)
```


## Summarising to mean ET for catchment
```{r}
SL_ET_mean <- SL_ET_no0 %>%
    group_by(Year,Jdate) %>%
    summarise(meanET = mean(ET, na.rm = T),
      sdET = sd(ET, na.rm = T))

head(SL_ET_mean)
```

add real dates and make a plot

```{r}
SL_ET_mean <- SL_ET_mean %>%
      mutate(Date = ymd(paste(Year,"01-01",sep="-")) +
      Jdate)
# Now, make a plot of the mean 8 daily ET
SL_ET_mean %>%
    ggplot(aes(Date, meanET)) +
    geom_line(colour="blue", size=1.2) +
    xlab("Time (8-daily)") + ylab("Basin average ET")
```

Look at mean and sd in two panels

```{r}
SL_ET_mean %>%
  gather(key = "variable", value="value", meanET, sdET) %>%
  ggplot(aes(Date, value, colour=variable)) +
  geom_line(size=1.2) +
  facet_wrap(~variable) +
  xlab("Time (8-daily)") + ylab("Basin average and sd ET")
```

## using GR4J with satellite data

Load the data and package: Santa Lucia basin

```{r}
require(hydromad)
load("data/PasoPache.Rdata")
```

Convert satellite data to a zoo object

```{r}
# Converting to a zoo format to work with hydromad
SL_MODISET <- zoo(SL_ET_mean$meanET, order.by=SL_ET_mean$Date)
head(SL_MODISET)
```

Load additional scripts to help the calibrations

```{r}
source("Rcode_IMFIA_course2018/leapfun.R")
source("Rcode_IMFIA_course2018/ETa.merge.R")
source("Rcode_IMFIA_course2018/plot.ET.R")
source("Rcode_IMFIA_course2018/ETfit.objectives.R")
```

Merge the PasoPache dataset with the satellite data

Use special function

```{r}
# discard the data before 2000
PP_data <- window(PasoPache, start="2000-01-01")
PP_Sat <- ETa.merge(Flowdata=PP_data,ETdata=SL_MODISET)
# Make a plot
xyplot(PP_Sat)
```

Define and calibrate GR4J model on Paso Pache streamflow

```{r}
data_cal <- window(PP_data, start = "2000-01-01",
                   end = "2005-12-31")
# Data for validation period
data_val <- window(PP_data, start = "2006-01-01",
                   end = "2010-12-31")
# Define the model, important to define return_state=T
# setting etmult = 1, as the data is potential ET
SL_mod <- hydromad(DATA=data_cal,
      sma = "gr4j", routing = "gr4jrouting",
      x1 = c(100,1000), x2 = c(-10,5),
      x3 = c(1,300),
      x4 = c(0.5,10), etmult=1,
      return_state=TRUE)
# Using shuffled complex evolution algorithm for fitting
SL_fit<- fitBySCE(SL_mod,
      objective= hmadstat("r.squared"))
# Extract the coefficients and the summary
summary(SL_fit)
```

Make a plot

```{r}
# plot
xyplot(SL_fit, with.P = TRUE)
```

## Fit also on the satellite data

```{r}
# remake the calibration data
data_modis_cal <- window(PP_Sat, start = "2000-01-01",
                         end = "2005-12-31")
# also make the validation data
data_modis_val <- window(PP_Sat, start = "2006-01-01",
                         end = "2010-12-31")
# Because we have rebuilt data.cal, redefine the model
SL_mod_Modis <- hydromad(DATA=data_modis_cal,
              sma = "gr4j", routing = "gr4jrouting",
              x1 = c(100,1000), x2 = c(-10,5),
              x3 = c(1,300), x4 = c(0.5,10),
              etmult=1,
              return_state=TRUE)
# fit both ET and Q using special objective function
SL_Fit_Modis <- fitBySCE(SL_mod_Modis,
        objective=~hmadstat("JointQandET")(Q,X,w=0.5,
        DATA=DATA,model=model,objf = hmadstat("r.squared")))
# check the model fit
summary(SL_Fit_Modis)
```

Make a plot of the predicted flow

```{r}
# Plotting the results
xyplot(SL_Fit_Modis, with.P = TRUE)
```

What we really want to see is how it predicts actual ET

use plot.ET function

```{r}
plot.ET(caldata=data_modis_cal,SL_Fit_Modis)
```

Compare coefficients and objective functions values

```{r}
coef(SL_fit)
coef(SL_Fit_Modis)
objFunVal(SL_fit)
objFunVal(SL_Fit_Modis)
```

Quick comparison of the overall Q fit
```{r}
as.vector(summary(SL_fit)[7:10])
as.vector(summary(SL_Fit_Modis)[7:10])

```

More formal comparison of the overall statistics

```{r}
# updating the model data for the validation
SL_val <- update(SL_fit, newdata = data_val)
SL_val_modis <- update(SL_Fit_Modis, newdata = data_modis_val)
# runlist
allMods <- runlist(calibration=SL_fit, validation=SL_val,
                  calibrationET=SL_Fit_Modis,
                  validationET= SL_val_modis)
# Get the summary results
round(summary(allMods),2)
```

The reason why the satellite calibration has little effect in this case is because the ET calculation in GR4J is independent from any of the parameters.





